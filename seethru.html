<!DOCTYPE html>
<html lang='en'>
<head>
<title>Web VR Boilerplate</title>
<meta charset='utf-8'>
<meta name='viewport' content='width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0, shrink-to-fit=no'>
<meta name='mobile-web-app-capable' content='yes'>
<meta name='apple-mobile-web-app-capable' content='yes' />
<meta name='apple-mobile-web-app-status-bar-style' content='black-translucent' />
<link rel='stylesheet' href='https://maxcdn.bootstrapcdn.com/font-awesome/4.6.2/css/font-awesome.min.css'>
<style>
html, body {
	width: 100%;
	height: 100%;
	background-color: #000;
	color: #fff;
	margin: 0px;
	padding: 0;
	overflow: hidden;
}

canvas {
	position: absolute;
	top: 0;
}
#fullScreenContainer {
	width: 100%;
	height: 100%;
	position: relative;
}

#buttons {
	position: absolute;
	bottom: 0;
	right: 0;
	z-index: 1;
	/*to prevent mouse selection of the button*/
	user-select: none;
	-webkit-user-select: none;
}
#buttons i {
	color: #ccc;
	font-size: 150%;
	margin-bottom: 0.4em;
	margin-right: 0.4em;
}
#buttons i:hover {
	color: #fff;
	text-shadow: 0px 0px 5px lightblue, 0px 0px 10px lightblue;
	cursor: pointer;
}
</style>
</head>

<body>
	<div id='fullScreenContainer'>
		<div style='position:absolute; top: 10px; width: 100%; text-align: center; font-family: Monospace; font-weight: bold; padding;color:grey; z-index: 1000;'>
			See thru example - using webvr and three.js
			<br/>
			<a href='javascript:void(0)' onclick='switchSource("video")' style='color: grey'>video</a>
			<a href='javascript:void(0)' onclick='switchSource("camera")' style='color: grey'>camera</a>
		</div>
		<div id='buttons'>
			<i class='fa fa-arrows-alt' id='fullscreenButton'></i>
			<i class='fa fa-eye' id='vrButton'></i>
			<i class='fa fa-star' id='resetButton' title='reset position'></i>
		</div>
	</div>
</body>

<script>
WebVRConfig = {
	BUFFER_SCALE: 0.5,
};

document.addEventListener('touchmove', function(event) {
	event.preventDefault();
});
</script>

<!-- three.js library -->
<script src='vendor/three.js/build/three.js'></script>

<!-- VRControls.js applies the WebVR transformations to a three.js camera object. -->
<script src='vendor/three.js/examples/js/controls/VRControls.js'></script>

<!-- VREffect.js handles stereo camera setup and rendering.  -->
<script src='vendor/three.js/examples/js/effects/VREffect.js'></script>
<!-- <script src='vendor/three.js/examples/js/effects/VREffect-fromweb.js'></script> -->

<!-- A polyfill for the WebVR API.  -->
<script src='vendor/webvr-polyfill.js'></script>


<script>
var onRenderFcts = []

// Setup three.js WebGL renderer. Note: Antialiasing is a big performance hit.
// Only enable it if you actually need to.
var renderer = new THREE.WebGLRenderer({antialias: false});
renderer.setPixelRatio(Math.floor(window.devicePixelRatio));

// Append the canvas element created by the renderer to fullScreenContainer
document.querySelector('#fullScreenContainer').appendChild(renderer.domElement);

// Create a three.js scene.
var scene = new THREE.Scene();

// Create a three.js camera.
var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 10000);

// Apply VR headset positional data to camera.
var controls = new THREE.VRControls(camera);

// Apply VR stereo rendering to renderer.
var effect = new THREE.VREffect(renderer);
effect.setSize(window.innerWidth, window.innerHeight);

// Get the VRDisplay and save it for later.
var vrDisplay = null;
navigator.getVRDisplays().then(function(displays) {
	if (displays.length > 0) {
		vrDisplay = displays[0];
	}
	
	if( vrDisplay !== null ){
		if( vrDisplay.capabilities.canPresent !== true ){
			document.querySelector('#vrButton').style.display = 'none'
		}
	}
});

// Request animation frame loop function
var lastRender = 0;
function animate(timestamp) {
	var delta = Math.min(timestamp - lastRender, 500);
	lastRender = timestamp;
	
	// Update VR headset position and apply to camera.
	controls.update();

	// call each function for the rendering
	onRenderFcts.forEach(function(onRenderFct){
		onRenderFct(delta)
	})
	
	// Render the scene.
	effect.render(scene, camera);
	
	// Keep looping.
	requestAnimationFrame(animate);
}

// Kick off animation loop.
requestAnimationFrame(animate);

//////////////////////////////////////////////////////////////////////////////////
//		Comments
//////////////////////////////////////////////////////////////////////////////////

function onResize() {
	effect.setSize(window.innerWidth, window.innerHeight);
	camera.aspect = window.innerWidth / window.innerHeight;
	camera.updateProjectionMatrix();
}

// Resize the WebGL canvas when we resize and also when we change modes.
window.addEventListener('resize', onResize);
window.addEventListener('vrdisplaypresentchange', function onVRDisplayPresentChange() {
	console.log('onVRDisplayPresentChange');
	onResize();
});

// Button click handlers.
document.querySelector('#fullscreenButton').addEventListener('click', function() {
	var domElement = document.querySelector('#fullScreenContainer')
	enterFullscreen(domElement);
});
document.querySelector('#vrButton').addEventListener('click', function() {
	vrDisplay.requestPresent([{source: renderer.domElement}]);
});
document.querySelector('#resetButton').addEventListener('click', function() {
	vrDisplay.resetPose();
});

renderer.domElement.addEventListener('click', function(event){
	var element = renderer.domElement
	// check it is the proper click
	if( event.target !== element )	return
	if( vrDisplay.displayName !== "Mouse and Keyboard VRDisplay (webvr-polyfill)")	return	
	// Ask the browser to lock the pointer
	element.requestPointerLock = element.requestPointerLock || element.mozRequestPointerLock || element.webkitRequestPointerLock;
	if ( /Firefox/i.test( navigator.userAgent ) ) {
		var fullscreenchange = function ( event ) {
			if ( document.fullscreenElement === element || document.mozFullscreenElement === element || document.mozFullScreenElement === element ) {
				document.removeEventListener( 'fullscreenchange', fullscreenchange );
				document.removeEventListener( 'mozfullscreenchange', fullscreenchange );
				element.requestPointerLock();
			}
		};
		document.addEventListener( 'fullscreenchange', fullscreenchange, false );
		document.addEventListener( 'mozfullscreenchange', fullscreenchange, false );
		element.requestFullscreen = element.requestFullscreen || element.mozRequestFullscreen || element.mozRequestFullScreen || element.webkitRequestFullscreen;
		element.requestFullscreen();
	} else {
		element.requestPointerLock();
	}
})

function enterFullscreen (element) {
	if (element.requestFullscreen) {
		element.requestFullscreen();
	} else if (element.mozRequestFullScreen) {
		element.mozRequestFullScreen();
	} else if (element.webkitRequestFullscreen) {
		element.webkitRequestFullscreen();
	} else if (element.msRequestFullscreen) {
		element.msRequestFullscreen();
	}
}

//////////////////////////////////////////////////////////////////////////////
//		Code Separator
//////////////////////////////////////////////////////////////////////////////

// Add a repeating grid as a skybox.
var boxWidth = 10;
var loader = new THREE.TextureLoader();
loader.load('images/box.png', function onTextureLoaded(texture) {
	texture.wrapS = THREE.RepeatWrapping;
	texture.wrapT = THREE.RepeatWrapping;
	texture.repeat.set(boxWidth, boxWidth);
	
	var geometry = new THREE.BoxGeometry(boxWidth, boxWidth, boxWidth);
	var material = new THREE.MeshBasicMaterial({
		map: texture,
		color: 0x01BE00,
		side: THREE.BackSide
	});
	
	var skybox = new THREE.Mesh(geometry, material);
	scene.add(skybox);
});

// Create 3D objects.
var geometry = new THREE.BoxGeometry(0.5, 0.5, 0.5);
var material = new THREE.MeshNormalMaterial();
var cube = new THREE.Mesh(geometry, material);
cube.position.z = -1

// Add cube mesh to your three.js scene
scene.add(cube);

// Position cube mesh
onRenderFcts.push(function(delta){
	cube.rotation.y += delta * 0.0006;
})


//////////////////////////////////////////////////////////////////////////////
//	plane always in front of the camera, exactly as big as the viewport
//////////////////////////////////////////////////////////////////////////////

var geometry = new THREE.PlaneGeometry(2, 2);
var material = new THREE.MeshBasicMaterial({
	map : new THREE.TextureLoader().load('images/UV_Grid_Sm.jpg'),
	side: THREE.DoubleSide,
	opacity: 0.5,
	transparent: true,
});
var seethruPlane = new THREE.Mesh(geometry, material);
seethruPlane.position.x = 0
seethruPlane.position.z = -1
scene.add(seethruPlane);

//////////////////////////////////////////////////////////////////////////////
//		Code Separator
//////////////////////////////////////////////////////////////////////////////

if( location.hash === '#video' ){
	var video = initSourceVideo(function onReady(){
		console.log('source video ready')
	})
	
}else if( location.hash === '#camera' || location.hash === '' ){
	var video = initSourceWebcam(function onReady(){
		console.log('source webcam ready')
	})	
}else {
	console.assert(false)
}

material.map = new THREE.VideoTexture( video );
material.map.minFilter = THREE.NearestFilter;
material.map.maxFilter = THREE.NearestFilter;
material.map.format = THREE.RGBFormat;
material.map.generateMipmaps = false;

onRenderFcts.push(function(delta){
	camera.updateMatrixWorld(true)
	
	// get seethruPlane position
	var position = new THREE.Vector3(0,0,-1)
	seethruPlane.position.copy(position)
	camera.localToWorld(seethruPlane.position)
	
	// get seethruPlane quaternion
	camera.matrixWorld.decompose( camera.position, camera.quaternion, camera.scale );	
	seethruPlane.quaternion.copy( camera.quaternion )
	
	// get seethruPlane height relative to fov
	seethruPlane.scale.y = Math.tan(THREE.Math.DEG2RAD * camera.fov/2)*position.length()

	// get seethruPlane aspect
	seethruPlane.scale.x = seethruPlane.scale.y * camera.aspect
})

window.addEventListener('resize', function(){
	updateSeeThruAspectUv(seethruPlane)	
})

video.addEventListener('canplaythrough', function(){
	updateSeeThruAspectUv(seethruPlane)
})

function updateSeeThruAspectUv(plane){
	if( video.videoWidth === 0 )	return
	if( video.videoHeight === 0 )	return

	var faceVertexUvs = plane.geometry.faceVertexUvs[0]
	var screenAspect = window.innerWidth / window.innerHeight
	var videoAspect = video.videoWidth / video.videoHeight
	
	plane.geometry.uvsNeedUpdate = true

	if( screenAspect >= videoAspect ){
		var actualHeight = videoAspect / screenAspect;
		// faceVertexUvs y 0
		faceVertexUvs[0][1].y = 0.5 - actualHeight/2
		faceVertexUvs[1][0].y = 0.5 - actualHeight/2
		faceVertexUvs[1][1].y = 0.5 - actualHeight/2

		// faceVertexUvs y 1
		faceVertexUvs[0][0].y = 0.5 + actualHeight/2
		faceVertexUvs[0][2].y = 0.5 + actualHeight/2
		faceVertexUvs[1][2].y = 0.5 + actualHeight/2
	}else{
		var actualWidth = screenAspect / videoAspect;

		// faceVertexUvs x 0
		faceVertexUvs[0][0].x = 0.5 - actualWidth/2
		faceVertexUvs[0][1].x = 0.5 - actualWidth/2
		faceVertexUvs[1][0].x = 0.5 - actualWidth/2
		
		// faceVertexUvs x 1
		faceVertexUvs[0][2].x = 0.5 + actualWidth/2
		faceVertexUvs[1][1].x = 0.5 + actualWidth/2
		faceVertexUvs[1][2].x = 0.5 + actualWidth/2
	}
}

//////////////////////////////////////////////////////////////////////////////////
//		Init
//////////////////////////////////////////////////////////////////////////////////

function initSourceVideo(onReady){
	var srcElement = document.createElement('video');
	srcElement.src = 'videos/sintel.mp4';
	srcElement.autoplay = true;
	srcElement.webkitPlaysinline = true;
	srcElement.controls = false;
	srcElement.loop = true;
	srcElement.volume = 0
	setTimeout(function(){
		onReady && onReady()
	}, 0)
	return srcElement
}

function initSourceImage(onReady){
	var srcElement = document.createElement('img')
	srcElement.src = './images/UV_Grid_Sm.jpg'
	// srcElement.src = './images/chalk.jpg'
	// srcElement.src = './images/chalk_multi.jpg'
	// srcElement.src = './images/kuva.jpg'
	// srcElement.src = './images/img.jpg'
	srcElement.width = 640
	srcElement.height = 480

	setTimeout(function(){
		onReady && onReady()
	}, 0)
	return srcElement
}

function initSourceWebcam(onReady){
	navigator.getUserMedia  = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia;

	var srcElement = document.createElement('video');
	document.body.appendChild(srcElement);

	if (navigator.getUserMedia == false )	console.log("navigator.getUserMedia not present in your browser");

	// get the media sources
	MediaStreamTrack.getSources(function(sourceInfos) {
		// define getUserMedia() constraints
		var constraints = {
			audio: false,
			video: {
				mandatory: {
					maxWidth: 640,
					maxHeight: 480
				}
			}
		}

		// it it finds the videoSource 'environment', modify constraints.video
		for (var i = 0; i != sourceInfos.length; ++i) {
			var sourceInfo = sourceInfos[i];
			if(sourceInfo.kind == "video" && sourceInfo.facing == "environment") {
				constraints.video.optional = [{sourceId: sourceInfo.id}]
			}
		}
		navigator.getUserMedia(constraints, function success(stream) {
			console.log('success', stream);
			srcElement.src = window.URL.createObjectURL(stream);
			// to start the video, when it is possible to start it only on userevent. like in android
			document.body.addEventListener('click', function(){
				srcElement.play();
			})
			srcElement.play();
		
			// wait until the video stream is ready
			var interval = setInterval(function() {
				if (!srcElement.videoWidth)	return;
				onReady()
				clearInterval(interval)
			}, 1000/100);
		}, function(error) {
			console.log("Can't access user media", error);
			alert("Can't access user media :()");
		});
	})

	return srcElement
}


function switchSource(sourceType){
	location.hash = '#'+sourceType
	location.reload()
}

</script></html>
